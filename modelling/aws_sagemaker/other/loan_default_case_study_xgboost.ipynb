{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29a94bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collinearity import SelectNonCollinear\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "164be768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: collinearity in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.6.1)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from collinearity) (0.24.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from collinearity) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn->collinearity) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn->collinearity) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn->collinearity) (1.5.3)\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c380be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'loandefaultbucket'\n",
    "dataset_filename = 'dataset.csv'\n",
    "subfolder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32392e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c035ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='loandefaultbucket'\n",
    "data_key = 'dataset.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00bb6c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://loandefaultbucket/dataset.csv'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'s3://sagemaker-us-east-1-590353062014/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f041e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.csv\n"
     ]
    }
   ],
   "source": [
    "conn = boto3.client('s3')\n",
    "contents = conn.list_objects(Bucket=bucket, Prefix=dataset_filename)['Contents']\n",
    "for f in contents:\n",
    "    print(f['Key'])\n",
    "    \n",
    "# response = conn.get_object(Bucket=bucket, Key=dataset_filename)\n",
    "# body = response['Body']\n",
    "# print(body)\n",
    "\n",
    "# df_data = pd.read_csv(response.get(\"Body\"), sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f7d40f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n"
     ]
    }
   ],
   "source": [
    "config_file = 'model_config.json'\n",
    "result = conn.get_object(Bucket=bucket, Key=config_file) \n",
    "model_config = result[\"Body\"].read().decode()\n",
    "model_config_json = json.loads(model_config)\n",
    "print(model_config_json['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aafb190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(conn, bucket, dataset_filename):\n",
    "    \"\"\"Load data from s3\"\"\"\n",
    "\n",
    "    response = conn.get_object(Bucket=bucket, Key=dataset_filename)\n",
    "    df_data = pd.read_csv(response.get(\"Body\"), sep=\";\")\n",
    "\n",
    "    df_train = df_data[~df_data['default'].isna()]\n",
    "    df_predict = df_data[df_data['default'].isna()]\n",
    "\n",
    "    return df_train, df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b33bf009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(bucket, key, var):\n",
    "    \n",
    "    pickle_byte_obj = pickle.dumps(var) \n",
    "    s3_resource = boto3.resource('s3')\n",
    "    s3_resource.Object(bucket,key).put(Body=pickle_byte_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "131ed937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucket='your_bucket_name'\n",
    "# key='your_pickle_filename.pkl'\n",
    "# pickle_byte_obj = pickle.dumps([var1, var2, ..., varn]) \n",
    "# s3_resource = boto3.resource('s3')\n",
    "# s3_resource.Object(bucket,key).put(Body=pickle_byte_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fae56341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprosessing_missing(data):\n",
    "    \"\"\"returns dataframe without missing values\"\"\"\n",
    "\n",
    "    # missing values\n",
    "    percent_missing = round(data.isnull().sum()/len(data) * 100, 2)\n",
    "    missing_value_df = pd.DataFrame({'column_name': data.columns,\n",
    "                                     'percent_missing': percent_missing})\n",
    "    # delete columns where missing data > 50%\n",
    "    col_to_delete = missing_value_df[missing_value_df['percent_missing'] > 49].index.to_list()\n",
    "\n",
    "#     np.savetxt(os.path.join(\"modelling\", \"removed_col_50_pct.csv\"),\n",
    "#                col_to_delete,\n",
    "#                delimiter=\",\",\n",
    "#                fmt='% s')\n",
    "\n",
    "    data = data.drop(col_to_delete, axis=1)\n",
    "    print(\"Removed columns with missing data > 50%:{}\".format(col_to_delete))\n",
    "\n",
    "    missing_30_pct = missing_value_df[(missing_value_df['percent_missing'] > 0) & (\n",
    "        missing_value_df['percent_missing'] < 30)].index.to_list()\n",
    "\n",
    "    # delete entries where missing data < 30%\n",
    "    # data = data.dropna()\n",
    "\n",
    "    # imput median where missing data <30%\n",
    "    for col in missing_30_pct:\n",
    "        data[col].fillna((data[col].median()), inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def data_preprosessing_collinearity(X, y, corr_threshold):\n",
    "    \"\"\"returns dataframe with eliminated correlated features\"\"\"\n",
    "\n",
    "    selector = SelectNonCollinear(correlation_threshold=corr_threshold)\n",
    "\n",
    "    features = X.select_dtypes(include=[\"number\"]).columns.to_list()\n",
    "\n",
    "    X_arr = X.select_dtypes(include=[\"number\"]).to_numpy()\n",
    "\n",
    "    selector.fit(X_arr, np.ravel(y))\n",
    "    mask = selector.get_support()\n",
    "\n",
    "    remove_corr_col = list(\n",
    "        set(X.select_dtypes(include=[\"number\"]))-set(np.array(features)[mask]))\n",
    "\n",
    "    # remove the highly correlated columns\n",
    "    X.drop(remove_corr_col, axis=1, inplace=True)\n",
    "\n",
    "#     np.savetxt(os.path.join(\"modelling\", \"removed_col_collinearity.csv\"),\n",
    "#                remove_corr_col,\n",
    "#                delimiter=\",\",\n",
    "#                fmt='% s')\n",
    "\n",
    "    print(\"Removed highly correlated columns:{}\".format(remove_corr_col))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def data_preprosessing_onehot(X):\n",
    "    \"\"\"returns dataframe with Onehot encoded categorical variables\"\"\"\n",
    "\n",
    "    categorical_col = X.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "    X_categorical = X[categorical_col]\n",
    "\n",
    "    encoder = OneHotEncoder(drop='first')\n",
    "    encoder.fit(X_categorical)\n",
    "    X_onehot = encoder.transform(X_categorical)\n",
    "\n",
    "    X_onehot_df = pd.DataFrame(X_onehot.toarray())\n",
    "\n",
    "#     pickle.dump(encoder, open(os.path.join(\n",
    "#         \"modelling\", \"one_hot_encoder.pkl\"), 'wb'))\n",
    "    save_pickle(bucket, \"one_hot_encoder.pkl\", encoder)\n",
    "\n",
    "    X_last = pd.concat([X.drop([\"merchant_category\", \"merchant_group\",\n",
    "                       \"name_in_email\"], axis=1), X_onehot_df.set_index(X.index)], axis=1)\n",
    "\n",
    "    return X_last\n",
    "\n",
    "\n",
    "def data_preprosessing_oversampling(X, y):\n",
    "    \"\"\"returns oversampled dataset and balanced target feature labels\"\"\"\n",
    "\n",
    "    # transform the dataset\n",
    "    oversample = SMOTE(random_state=101)\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_model_rf(X, y, bucket):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=0, test_size=0.3, stratify=y)\n",
    "\n",
    "    # train a randomforest classifier\n",
    "    rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "    rf_clf.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    # save trained model\n",
    "#     pickle.dump(rf_clf, open(os.path.join(\n",
    "#         \"modelling\", \"rf_clf_model.pkl\"), 'wb'))\n",
    "    save_pickle(bucket, \"rf_clf_model.pkl\", rf_clf)\n",
    "\n",
    "    return rf_clf\n",
    "\n",
    "\n",
    "def data_preprosessing(data, corr_threshold):\n",
    "    \"\"\"prepares data for input to model, returns transformend dataframe\"\"\"\n",
    "\n",
    "    # missing data\n",
    "    data = data_preprosessing_missing(data)\n",
    "\n",
    "    X = data.drop([\"uuid\", \"default\"], axis=1)\n",
    "    y = data[[\"default\"]]\n",
    "\n",
    "    # remove collinearity\n",
    "    X, y = data_preprosessing_collinearity(X, y, corr_threshold)\n",
    "    # onehot encoder\n",
    "    X = data_preprosessing_onehot(X)\n",
    "    # oversampling\n",
    "    X, y = data_preprosessing_oversampling(X, y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def data_prep_predict(data, target, selected_features, categorical_features, bucket):\n",
    "    \"\"\"function to prepare data for input to model for prediction\"\"\"\n",
    "\n",
    "    # check for default column in test data\n",
    "    if target in data.columns:\n",
    "        data = data[data[\"default\"].isna()].drop([\"default\"], axis=1).reset_index(drop=True)\n",
    "\n",
    "    # check for all required features\n",
    "    for col_name in selected_features:\n",
    "        if col_name not in data.columns:\n",
    "            raise Exception('Required column  is missing:{}', format(col_name))\n",
    "\n",
    "#     print('Writing the data to csv file where required column values are missing')\n",
    "\n",
    "#     data[data[selected_features].isnull().any(axis=1)].to_csv(os.path.join(\n",
    "#         \"predict\", 'required_columns_values_missing.csv'))\n",
    "\n",
    "    # data.dropna(subset=selected_features, inplace=True)\n",
    "\n",
    "    # input median where missing data <30%\n",
    "    for col in selected_features:\n",
    "        if data[col].isnull().sum() != 0:\n",
    "            data[col] = data[col].fillna(data[col].median())\n",
    "    \n",
    "    selected_features.append('uuid')\n",
    "    \n",
    "    # filter selected features\n",
    "    data = data[selected_features]\n",
    "\n",
    "    # onehot encoding\n",
    "    df_categorical = data[categorical_features]\n",
    "\n",
    "#     encoder = pickle.load(open(os.path.join(\"modelling\", \"one_hot_encoder.pkl\"), 'rb'))\n",
    "\n",
    "    encoder = load_pickle(bucket, \"one_hot_encoder.pkl\")\n",
    "    data_one_hot = encoder.transform(df_categorical)\n",
    "    df_data_one_hot = pd.DataFrame(data_one_hot.toarray())\n",
    "    data_last = pd.concat([data.drop(categorical_features, axis = 1), \n",
    "                            df_data_one_hot.set_index(data.index)],axis=1)\n",
    "\n",
    "    return data_last\n",
    "\n",
    "\n",
    "def predict_default(data_last):\n",
    "    \"\"\"function to predict the probability of default and write the result to prediction_default.csv file\"\"\"\n",
    "\n",
    "    # load trained model\n",
    "#     rf_clf = pickle.load(open(os.path.join(\"modelling\", \"rf_clf_model.pkl\"), 'rb'))\n",
    "    rf_clf = load_pickle(bucket, \"rf_clf_model.pkl\")\n",
    "\n",
    "    if 'uuid' in data_last.columns:\n",
    "\n",
    "        data_last['pd_prediction'] = rf_clf.predict(data_last.drop([\"uuid\"], axis=1))\n",
    "        df_predicted = data_last[['uuid', 'pd_prediction']]\n",
    "    else:\n",
    "        data_last['pd_prediction'] = rf_clf.predict(data_last)\n",
    "        df_predicted = data_last['pd_prediction']\n",
    "\n",
    "#     df_predicted.to_csv(os.path.join(\"predict\",'prediction_default.csv'))\n",
    "\n",
    "#     print('Check predicted pd in: ../predict/prediction_default.csv')\n",
    "    \n",
    "    return df_predicted\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04a395e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(bucket, pickle_name):\n",
    "    s3 = boto3.resource('s3')\n",
    "    pickle_content = pickle.loads(s3.Bucket(bucket).Object(pickle_name).get()['Body'].read())\n",
    "    \n",
    "    return pickle_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ef92092",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = model_config_json[\"target\"]\n",
    "selected_features = model_config_json[\"selected_features\"]\n",
    "categorical_features = model_config_json[\"categorical_features\"]\n",
    "corr_threshold = model_config_json[\"corr_threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d8f7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Load Data\n",
    "df_train, df_predict = load_data(conn, bucket, dataset_filename)\n",
    "# print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cc6b589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 43)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55632d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns with missing data > 50%:['account_incoming_debt_vs_paid_0_24m', 'account_status', 'account_worst_status_0_3m', 'account_worst_status_12_24m', 'account_worst_status_3_6m', 'account_worst_status_6_12m', 'avg_payment_span_0_3m', 'worst_status_active_inv']\n",
      "Removed highly correlated columns:['status_max_archived_0_12_months', 'max_paid_inv_0_12m', 'num_arch_ok_12_24m']\n"
     ]
    }
   ],
   "source": [
    "# use part  2 and 3 when training the model\n",
    "# 2.Data preprosessing\n",
    "X, y = data_preprosessing(df_train, corr_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e202805e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.Train model\n",
    "train_model_rf(X, y, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d7c66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use part 4 to make prediction\n",
    "# 4.Prediction\n",
    "X_prep = data_prep_predict(df_predict, target, selected_features, categorical_features, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3751c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = predict_default(X_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dc1e84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>pd_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6f6e6c6a-2081-4e6b-8eb3-4fd89b54b2d7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f6f6d9f3-ef2b-4329-a388-c6a687f27e70</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e9c39869-1bc5-4375-b627-a2df70b445ea</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6beb88a3-9641-4381-beb6-c9a208664dd0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb89b735-72fe-42a4-ba06-d63be0f4ca36</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid  pd_prediction\n",
       "0  6f6e6c6a-2081-4e6b-8eb3-4fd89b54b2d7            0.0\n",
       "1  f6f6d9f3-ef2b-4329-a388-c6a687f27e70            0.0\n",
       "2  e9c39869-1bc5-4375-b627-a2df70b445ea            0.0\n",
       "3  6beb88a3-9641-4381-beb6-c9a208664dd0            0.0\n",
       "4  bb89b735-72fe-42a4-ba06-d63be0f4ca36            0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66b0b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "bucket = sagemaker.session.Session().default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc87c43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-1-590353062014'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12428586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri \n",
    "from sagemaker.session import s3_input, Session\n",
    "            \n",
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"50\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a76c2e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set an output path where the trained model will be saved\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'DEMO-xgboost-as-a-built-in-algo'\n",
    "output_path = 's3://{}/{}/{}/output'.format(bucket, prefix, 'abalone-xgb-built-in-algo')\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "\n",
    "# xgboost_container = get_image_uri(boto3.Session().region_name,\n",
    "#                           'xgboost', \n",
    "#                           repo_version='1.2-2')\n",
    "\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"latest\")\n",
    "display(xgboost_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da5885c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'image_uri'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bb628470f11a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                           \u001b[0minstance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ml.t2.medium'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                           \u001b[0mtrain_volume_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 5 GB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                           output_path=output_path)\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'image_uri'"
     ]
    }
   ],
   "source": [
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_name=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.t2.medium', \n",
    "                                          train_volume_size=1, # 5 GB \n",
    "                                          output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17baeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05a2c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"study-case-xgboost-churn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71ae1286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"latest\")\n",
    "display(xgboost_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94aacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_input_train = TrainingInput(\n",
    "#     s3_data=\"s3://{}/{}/train\".format(bucket, prefix), content_type=\"csv\"\n",
    "# )\n",
    "# s3_input_validation = TrainingInput(\n",
    "#     s3_data=\"s3://{}/{}/validation/\".format(bucket, prefix), content_type=\"csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf6bd2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    xgboost_container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "xgb.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    silent=0,\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a447c545",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot format input         account_amount_added_12_24m  account_days_in_dc_12_24m  \\\n0                                 0                        0.0   \n1                                 0                        0.0   \n2                                 0                        0.0   \n3                                 0                        0.0   \n4                                 0                        0.0   \n...                             ...                        ...   \n177371                            0                        0.0   \n177372                        32058                        0.0   \n177373                        19151                        0.0   \n177374                            0                        0.0   \n177375                        96619                        0.0   \n\n        account_days_in_rem_12_24m  account_days_in_term_12_24m  age  \\\n0                         0.000000                          0.0   20   \n1                         0.000000                          0.0   50   \n2                         0.000000                          0.0   22   \n3                         0.000000                          0.0   36   \n4                         0.000000                          0.0   25   \n...                            ...                          ...  ...   \n177371                    0.000000                          0.0   33   \n177372                   68.604513                          0.0   23   \n177373                  105.973431                          0.0   28   \n177374                    0.000000                          0.0   23   \n177375                   79.020063                          0.0   46   \n\n        avg_payment_span_0_12m  has_paid  max_paid_inv_0_24m  \\\n0                    12.692308      True        31638.000000   \n1                    25.833333      True        13749.000000   \n2                    20.000000      True        29890.000000   \n3                     4.687500      True        40040.000000   \n4                    13.000000      True         7100.000000   \n...                        ...       ...                 ...   \n177371               83.770783      True        10652.112296   \n177372               98.726862      True         7935.794445   \n177373               14.904762      True         1231.584178   \n177374               12.772537      True         7545.690910   \n177375               56.736887      True         7546.061458   \n\n        num_active_div_by_paid_inv_0_12m  num_active_inv  ...   64   65  \\\n0                               0.153846               2  ...  0.0  0.0   \n1                               0.000000               0  ...  0.0  0.0   \n2                               0.071429               1  ...  0.0  0.0   \n3                               0.031250               1  ...  0.0  0.0   \n4                               0.000000               0  ...  0.0  0.0   \n...                                  ...             ...  ...  ...  ...   \n177371                          0.000000               0  ...  0.0  0.0   \n177372                          0.000000               0  ...  0.0  0.0   \n177373                          0.000000               1  ...  0.0  0.0   \n177374                          0.000000               0  ...  0.0  0.0   \n177375                          0.000000               0  ...  0.0  0.0   \n\n              66        67   68   69        70   71        72        73  \n0       0.000000  0.000000  0.0  0.0  0.000000  0.0  0.000000  1.000000  \n1       0.000000  1.000000  0.0  0.0  0.000000  0.0  0.000000  0.000000  \n2       0.000000  0.000000  0.0  0.0  0.000000  1.0  0.000000  0.000000  \n3       0.000000  0.000000  1.0  0.0  0.000000  0.0  0.000000  0.000000  \n4       0.000000  1.000000  0.0  0.0  0.000000  0.0  0.000000  0.000000  \n...          ...       ...  ...  ...       ...  ...       ...       ...  \n177371  0.000000  0.147506  0.0  0.0  0.000000  0.0  0.000000  0.852494  \n177372  0.000000  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.980064  \n177373  0.000000  0.447360  0.0  0.0  0.000000  0.0  0.000000  0.552640  \n177374  0.049064  0.000000  0.0  0.0  0.049064  0.0  0.950936  0.000000  \n177375  0.000000  1.000000  0.0  0.0  0.000000  0.0  0.000000  0.000000  \n\n[177376 rows x 101 columns]. Expecting one of str, TrainingInput, file_input or FileSystemInput",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0d8a0d64e67d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0mall\u001b[0m \u001b[0minformation\u001b[0m \u001b[0mabout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstarted\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \"\"\"\n\u001b[0;32m-> 1470\u001b[0;31m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36m_get_train_args\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1508\u001b[0m                 )\n\u001b[1;32m   1509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1510\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0mcurrent_hyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/job.py\u001b[0m in \u001b[0;36m_load_config\u001b[0;34m(inputs, estimator, expand_role, validate_uri)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;34m\"\"\"Placeholder docstring\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0minput_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_inputs_to_input_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         role = (\n\u001b[1;32m     69\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/job.py\u001b[0m in \u001b[0;36m_format_inputs_to_input_config\u001b[0;34m(inputs, validate_uri)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_string_uri_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0minput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_record_set_list_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/job.py\u001b[0m in \u001b[0;36m_format_string_uri_input\u001b[0;34m(uri_input, validate_uri, content_type, input_mode, compression, target_attribute_name)\u001b[0m\n\u001b[1;32m    198\u001b[0m         raise ValueError(\n\u001b[1;32m    199\u001b[0m             \u001b[0;34m\"Cannot format input {}. Expecting one of str, TrainingInput, file_input or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;34m\"FileSystemInput\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         )\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot format input         account_amount_added_12_24m  account_days_in_dc_12_24m  \\\n0                                 0                        0.0   \n1                                 0                        0.0   \n2                                 0                        0.0   \n3                                 0                        0.0   \n4                                 0                        0.0   \n...                             ...                        ...   \n177371                            0                        0.0   \n177372                        32058                        0.0   \n177373                        19151                        0.0   \n177374                            0                        0.0   \n177375                        96619                        0.0   \n\n        account_days_in_rem_12_24m  account_days_in_term_12_24m  age  \\\n0                         0.000000                          0.0   20   \n1                         0.000000                          0.0   50   \n2                         0.000000                          0.0   22   \n3                         0.000000                          0.0   36   \n4                         0.000000                          0.0   25   \n...                            ...                          ...  ...   \n177371                    0.000000                          0.0   33   \n177372                   68.604513                          0.0   23   \n177373                  105.973431                          0.0   28   \n177374                    0.000000                          0.0   23   \n177375                   79.020063                          0.0   46   \n\n        avg_payment_span_0_12m  has_paid  max_paid_inv_0_24m  \\\n0                    12.692308      True        31638.000000   \n1                    25.833333      True        13749.000000   \n2                    20.000000      True        29890.000000   \n3                     4.687500      True        40040.000000   \n4                    13.000000      True         7100.000000   \n...                        ...       ...                 ...   \n177371               83.770783      True        10652.112296   \n177372               98.726862      True         7935.794445   \n177373               14.904762      True         1231.584178   \n177374               12.772537      True         7545.690910   \n177375               56.736887      True         7546.061458   \n\n        num_active_div_by_paid_inv_0_12m  num_active_inv  ...   64   65  \\\n0                               0.153846               2  ...  0.0  0.0   \n1                               0.000000               0  ...  0.0  0.0   \n2                               0.071429               1  ...  0.0  0.0   \n3                               0.031250               1  ...  0.0  0.0   \n4                               0.000000               0  ...  0.0  0.0   \n...                                  ...             ...  ...  ...  ...   \n177371                          0.000000               0  ...  0.0  0.0   \n177372                          0.000000               0  ...  0.0  0.0   \n177373                          0.000000               1  ...  0.0  0.0   \n177374                          0.000000               0  ...  0.0  0.0   \n177375                          0.000000               0  ...  0.0  0.0   \n\n              66        67   68   69        70   71        72        73  \n0       0.000000  0.000000  0.0  0.0  0.000000  0.0  0.000000  1.000000  \n1       0.000000  1.000000  0.0  0.0  0.000000  0.0  0.000000  0.000000  \n2       0.000000  0.000000  0.0  0.0  0.000000  1.0  0.000000  0.000000  \n3       0.000000  0.000000  1.0  0.0  0.000000  0.0  0.000000  0.000000  \n4       0.000000  1.000000  0.0  0.0  0.000000  0.0  0.000000  0.000000  \n...          ...       ...  ...  ...       ...  ...       ...       ...  \n177371  0.000000  0.147506  0.0  0.0  0.000000  0.0  0.000000  0.852494  \n177372  0.000000  0.000000  0.0  0.0  0.000000  0.0  0.000000  0.980064  \n177373  0.000000  0.447360  0.0  0.0  0.000000  0.0  0.000000  0.552640  \n177374  0.049064  0.000000  0.0  0.0  0.049064  0.0  0.950936  0.000000  \n177375  0.000000  1.000000  0.0  0.0  0.000000  0.0  0.000000  0.000000  \n\n[177376 rows x 101 columns]. Expecting one of str, TrainingInput, file_input or FileSystemInput"
     ]
    }
   ],
   "source": [
    "xgb.fit({\"train\": X, \"validation\": y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4911005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
